# üìä PERSON REID SYSTEM - PERFORMANCE BENCHMARK REPORT

**Date**: 2025-11-12  
**System**: 4x Tesla V100-SXM2-16GB (64GB total VRAM), 80-core Xeon Gold 6148, 251GB RAM

---

## üéØ EXECUTIVE SUMMARY

**Current Performance**: **KH√îNG ƒê·∫†T REAL-TIME** v·ªõi 2 camera streams  
**Bottleneck ch√≠nh**: **Detection (ByteTrack) - chi·∫øm 88.3% th·ªùi gian x·ª≠ l√Ω**  
**Frame drop rate**: **80-92%** - R·∫•t cao, kh√¥ng ch·∫•p nh·∫≠n ƒë∆∞·ª£c cho production

---

## üìà TEST 1: SINGLE VIDEO FILE (cam1.mkv)

### Video Info
- **Resolution**: 1280x720
- **FPS**: 25.0
- **Format**: H.264 (MKV container)
- **Size**: 7.7MB

### Performance Results
```
‚è±Ô∏è  PROCESSING PERFORMANCE:
  Total frames:        250
  Elapsed time:        23.51s
  Average FPS:         10.64
  Video FPS:           25.00
  Real-time factor:    0.43x  ‚ö†Ô∏è (C·∫ßn 2.35x speedup)
  Dropped frames:      202 (80.8%)
```

### Component Breakdown
```
üîç COMPONENT BREAKDOWN (ms):
  Detection:    avg= 57.96  max=120.92  min= 40.15
  Tracking:     avg=  2.44  max=  5.30  min=  1.32
  ReID:         avg=  2.51  max= 72.07  min=  0.01
  Total/frame:  avg= 65.65  max=139.69  min= 42.91

üìà TIME DISTRIBUTION:
  Detection:     88.3%  ‚ö†Ô∏è BOTTLENECK
  Tracking:       3.7%
  ReID:           3.8%
  Other:          4.2%
```

### System Resources
```
üíª SYSTEM RESOURCES:
  GPU Util:     avg= 11.3%  max= 29.0%  ‚ö†Ô∏è Underutilized
  GPU Memory:   avg= 47.6%  max= 47.7%
  CPU Util:     avg= 17.8%  max= 26.8%
  RAM Util:     avg= 36.0%  max= 36.1%
```

---

## üìà TEST 2: DUAL CAMERA STREAMS (UDP)

### Stream Info
- **Streams**: 2x UDP streams (ports 1905, 1906)
- **Source**: Same cam1.mkv video (looped)
- **Protocol**: UDP/MPEGTS
- **Duration**: 30 seconds

### Performance Results
```
‚è±Ô∏è  OVERALL PERFORMANCE:
  Duration:            32.14s
  Total frames:        299
  Combined FPS:        9.30  ‚ö†Ô∏è R·∫•t th·∫•p
  Dropped frames:      276 (92.3%)  ‚ö†Ô∏è C·ª±c k·ª≥ cao
```

### Per-Stream Breakdown
```
üìπ STREAM 0:
  Frames:          81
  FPS:             2.44  ‚ö†Ô∏è Ch·ªâ 10% c·ªßa video FPS
  Dropped:         60 (74.1%)
  Detection:       avg= 53.96ms  max= 95.26ms
  Tracking:        avg=  2.13ms  max=  6.82ms
  ReID:            avg= 49.64ms  max=3788.90ms  ‚ö†Ô∏è Spike l·ªõn

üìπ STREAM 1:
  Frames:          218
  FPS:             6.58  ‚ö†Ô∏è Ch·ªâ 26% c·ªßa video FPS
  Dropped:         216 (99.1%)  ‚ö†Ô∏è G·∫ßn nh∆∞ drop to√†n b·ªô
  Detection:       avg= 72.24ms  max=185.04ms  ‚ö†Ô∏è Ch·∫≠m h∆°n stream 0
  Tracking:        avg=  2.22ms  max=  5.16ms
  ReID:            avg=  2.81ms  max= 79.26ms
```

### System Resources
```
üíª SYSTEM RESOURCES:
  GPU Util:        avg=  9.6%  max= 48.0%  ‚ö†Ô∏è R·∫•t th·∫•p
  GPU Memory:      avg= 47.7%  max= 48.0%
  CPU Util:        avg= 18.0%  max= 30.6%
  RAM Util:        avg= 35.9%  max= 36.0%
```

---

## üîç ROOT CAUSE ANALYSIS

### 1. **Detection Bottleneck (88.3% th·ªùi gian)**
- **Triton ByteTrack TensorRT**: 54-72ms/frame (avg ~60ms)
- **Expected**: ~10-15ms/frame cho TensorRT FP16
- **V·∫•n ƒë·ªÅ**: 
  - ‚ùå Triton ch·∫°y **SEQUENTIAL** (kh√¥ng batch)
  - ‚ùå Dynamic batching **DISABLED** trong config
  - ‚ùå M·ªói stream g·ªçi Triton ri√™ng l·∫ª ‚Üí kh√¥ng t·∫≠n d·ª•ng batching
  - ‚ùå GPU utilization ch·ªâ 9-11% ‚Üí GPU idle ph·∫ßn l·ªõn th·ªùi gian

### 2. **Multi-Stream Contention**
- 2 streams c√πng g·ªçi Triton ‚Üí **serialize** requests
- Stream 1 ch·∫≠m h∆°n Stream 0 (72ms vs 54ms) ‚Üí ch·ªù ƒë·ª£i l·∫´n nhau
- Kh√¥ng c√≥ queue management ‚Üí frame drops

### 3. **ReID Spikes**
- Stream 0 c√≥ spike l√™n **3788ms** (3.8 gi√¢y!) cho 1 frame
- Nguy√™n nh√¢n: InsightFace face detection th·∫•t b·∫°i nhi·ªÅu l·∫ßn
- Kh√¥ng c√≥ timeout mechanism

### 4. **GPU Underutilization**
- GPU 0: 9-11% utilization (should be 60-80%)
- GPU 1-3: **IDLE** (0% usage)
- Kh√¥ng t·∫≠n d·ª•ng multi-GPU

---

## üí° RECOMMENDED SOLUTIONS

### ‚úÖ SOLUTION 1: Enable Dynamic Batching (Quick Win)
**Impact**: 2-3x speedup  
**Effort**: 5 minutes

**Action**:
```protobuf
# triton_model_repository/bytetrack_tensorrt/config.pbtxt
dynamic_batching {
  preferred_batch_size: [ 2, 4 ]
  max_queue_delay_microseconds: 5000
}
```

**Expected Result**:
- 2 streams ‚Üí batch size 2 ‚Üí ~30ms/batch ‚Üí 15ms/frame
- FPS: 10.64 ‚Üí **~20-25 FPS** (real-time cho 1 stream)

---

### ‚úÖ SOLUTION 2: Add ArcFace to Triton on GPU 1 (Recommended)
**Impact**: 10-16x speedup cho ReID, gi·∫£m spikes  
**Effort**: 1 hour

**Benefits**:
- Lo·∫°i b·ªè ReID spikes (3788ms ‚Üí <10ms)
- Batch processing cho faces
- T√°ch workload: GPU 0 (Detection) + GPU 1 (ReID)
- Support 8-16+ cameras

**Steps**:
1. Convert ArcFace ONNX ‚Üí TensorRT
2. Setup Triton model repository
3. Create `core/feature_extractor_triton.py`
4. Update config

---

### ‚úÖ SOLUTION 3: Optimize Triton Config (Medium Win)
**Impact**: 1.5-2x speedup  
**Effort**: 15 minutes

**Actions**:
```protobuf
# Increase instances
instance_group [
  {
    count: 8  # Reduce from 16 to 8 (enough for 2-4 streams)
    kind: KIND_GPU
    gpus: [ 0 ]
  }
]

# Enable CUDA graphs
optimization {
  cuda {
    graphs: true
  }
}
```

---

### ‚úÖ SOLUTION 4: Implement Frame Skipping Strategy
**Impact**: Maintain real-time at cost of some frames  
**Effort**: 30 minutes

**Logic**:
- If processing time > frame interval ‚Üí skip next frame
- Adaptive skip rate based on queue depth
- Prioritize tracking continuity over all frames

---

## üìä PROJECTED PERFORMANCE (After Optimizations)

### Scenario 1: Dynamic Batching Only
```
Single stream:  10.64 ‚Üí 20-25 FPS  ‚úÖ Real-time
Dual streams:   9.30  ‚Üí 15-18 FPS  ‚ö†Ô∏è Marginal
```

### Scenario 2: Dynamic Batching + ArcFace Triton
```
Single stream:  10.64 ‚Üí 25-30 FPS  ‚úÖ Real-time+
Dual streams:   9.30  ‚Üí 20-25 FPS  ‚úÖ Real-time
4 streams:      N/A   ‚Üí 12-15 FPS  ‚ö†Ô∏è Marginal
8 streams:      N/A   ‚Üí 8-10 FPS   ‚ùå Below real-time
```

### Scenario 3: Full Optimization (All solutions)
```
Single stream:  10.64 ‚Üí 30-35 FPS  ‚úÖ Real-time++
Dual streams:   9.30  ‚Üí 25-30 FPS  ‚úÖ Real-time+
4 streams:      N/A   ‚Üí 15-20 FPS  ‚úÖ Real-time
8 streams:      N/A   ‚Üí 10-12 FPS  ‚ö†Ô∏è Marginal
16 streams:     N/A   ‚Üí 6-8 FPS    ‚ùå Below real-time
```

---

## üéØ NEXT STEPS

### Immediate (Today)
1. ‚úÖ **Enable dynamic batching** trong Triton config
2. ‚úÖ **Test l·∫°i** v·ªõi 2 streams
3. ‚úÖ **Measure improvement**

### Short-term (This Week)
1. ‚úÖ **Convert ArcFace to TensorRT**
2. ‚úÖ **Add ArcFace to Triton** on GPU 1
3. ‚úÖ **Integrate** v√†o pipeline
4. ‚úÖ **Benchmark** v·ªõi 4-8 streams

### Medium-term (Next Week)
1. ‚è∏Ô∏è Implement frame skipping strategy
2. ‚è∏Ô∏è Add monitoring dashboard
3. ‚è∏Ô∏è Optimize preprocessing pipeline
4. ‚è∏Ô∏è Consider model quantization (INT8)

---

## üìù CONCLUSION

**Current State**: System **KH√îNG ƒê·∫†T** real-time performance cho 2 cameras  
**Root Cause**: Detection bottleneck (88.3%) do kh√¥ng d√πng batching  
**Quick Fix**: Enable dynamic batching ‚Üí 2-3x speedup  
**Long-term**: Add ArcFace to Triton ‚Üí support 8-16 cameras  

**Recommendation**: Tri·ªÉn khai Solution 1 (dynamic batching) ngay l·∫≠p t·ª©c, sau ƒë√≥ Solution 2 (ArcFace Triton) trong tu·∫ßn n√†y.

