# TensorRT Integration - Dependencies & Requirements

## üìã OVERVIEW

T√†i li·ªáu n√†y ghi l·∫°i to√†n b·ªô dependencies v√† requirements ƒë·ªÉ ch·∫°y h·ªá th·ªëng Person ReID v·ªõi TensorRT optimization.

---

## üñ•Ô∏è SYSTEM REQUIREMENTS

### Hardware
- **GPU**: NVIDIA Tesla V100 (SM 70 - Volta architecture)
- **CUDA Compute Capability**: 7.0
- **GPU Memory**: 16GB+ recommended
- **System RAM**: 32GB+ recommended

### Software
- **OS**: Ubuntu 20.04/22.04
- **CUDA**: 12.8 (system-wide installation)
- **Python**: 3.10.x (REQUIRED - TensorRT 8.6.1 kh√¥ng h·ªó tr·ª£ Python 3.12)

---

## üêç PYTHON ENVIRONMENT

### Virtual Environment Setup
```bash
# T·∫°o virtual environment v·ªõi Python 3.10
python3.10 -m venv ~/data/hai_venv_py310

# Activate
source ~/data/hai_venv_py310/bin/activate

# Verify Python version
python --version  # Ph·∫£i l√† Python 3.10.x
```

---

## üì¶ CORE DEPENDENCIES

### 1. PyTorch Stack (CRITICAL VERSION REQUIREMENTS)

**‚ö†Ô∏è QUAN TR·ªåNG: Ph·∫£i d√πng PyTorch 2.0.1 ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi CUDNN 8.x**

```bash
pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 \
    --index-url https://download.pytorch.org/whl/cu118
```

**L√Ω do:**
- PyTorch 2.5.x y√™u c·∫ßu CUDNN 9.x
- TensorRT 8.6.1 y√™u c·∫ßu CUDNN 8.x
- PyTorch 2.0.1 t∆∞∆°ng th√≠ch v·ªõi CUDNN 8.x

**Dependencies c·ªßa PyTorch 2.0.1:**
- `triton==2.0.0` (auto-installed)
- `sympy==1.13.1`
- `networkx`
- `jinja2`
- `filelock`
- `typing-extensions`

### 2. TensorRT (CRITICAL VERSION)

**‚ö†Ô∏è QUAN TR·ªåNG: Ph·∫£i d√πng TensorRT 8.6.1 cho GPU SM 70 (V100)**

```bash
pip install tensorrt==8.6.1.post1 --extra-index-url https://pypi.nvidia.com
```

**L√Ω do:**
- TensorRT 10.x ch·ªâ h·ªó tr·ª£ SM 75+ (Turing v√† m·ªõi h∆°n)
- TensorRT 8.6.1 h·ªó tr·ª£ SM 70 (Volta/V100)
- TensorRT 8.6.1 ch·ªâ c√≥ bindings cho Python 3.10, kh√¥ng c√≥ cho Python 3.12

**Dependencies c·ªßa TensorRT 8.6.1:**
- `tensorrt-libs==8.6.1.post1` (auto-installed)
- `tensorrt-bindings==8.6.1` (auto-installed)

### 3. CUDNN (CRITICAL VERSION)

**‚ö†Ô∏è QUAN TR·ªåNG: Ph·∫£i d√πng CUDNN 8.9.6.50**

```bash
pip install nvidia-cudnn-cu12==8.9.6.50 --no-deps
```

**L√Ω do:**
- TensorRT 8.6.1 y√™u c·∫ßu CUDNN 8.x
- PyTorch 2.0.1 t∆∞∆°ng th√≠ch v·ªõi CUDNN 8.x
- CUDNN 9.x kh√¥ng t∆∞∆°ng th√≠ch v·ªõi TensorRT 8.6.1

### 4. PyCUDA

```bash
pip install pycuda
```

**Dependencies:**
- C·∫ßn CUDA toolkit ƒë√£ c√†i ƒë·∫∑t tr√™n system
- S·ª≠ d·ª•ng cho GPU memory management trong TensorRT

### 5. NumPy (CRITICAL VERSION)

**‚ö†Ô∏è QUAN TR·ªåNG: Ph·∫£i d√πng NumPy < 2.0**

```bash
pip install "numpy<2"
```

**L√Ω do:**
- PyTorch 2.0.1 kh√¥ng t∆∞∆°ng th√≠ch v·ªõi NumPy 2.x
- NumPy 2.x c√≥ breaking changes v·ªõi compiled modules
- Recommended: `numpy==1.26.4`

### 6. ONNX Stack

```bash
pip install onnx onnxruntime-gpu
```

**Versions:**
- `onnx>=1.14.0` (latest compatible)
- `onnxruntime-gpu>=1.15.0` (for ONNX verification)

---

## üì¶ PROJECT DEPENDENCIES

### Computer Vision & ML
```bash
pip install opencv-python scipy pillow
```

### YOLOX Dependencies
```bash
pip install thop tabulate tqdm pycocotools
```

### Tracking & ReID
```bash
pip install lap cython_bbox
```

### Utilities
```bash
pip install loguru pyyaml python-dotenv
```

### Vector Database (Optional - for ReID)
```bash
pip install qdrant-client
```

---

## üîß COMPLETE INSTALLATION SCRIPT

```bash
#!/bin/bash

# 1. Create Python 3.10 virtual environment
python3.10 -m venv ~/data/hai_venv_py310
source ~/data/hai_venv_py310/bin/activate

# 2. Upgrade pip
pip install --upgrade pip

# 3. Install PyTorch 2.0.1 (CUDA 11.8)
pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 \
    --index-url https://download.pytorch.org/whl/cu118

# 4. Install NumPy < 2.0
pip install "numpy<2"

# 5. Install TensorRT 8.6.1
pip install tensorrt==8.6.1.post1 --extra-index-url https://pypi.nvidia.com

# 6. Install CUDNN 8.9.6.50
pip install nvidia-cudnn-cu12==8.9.6.50 --no-deps

# 7. Install PyCUDA
pip install pycuda

# 8. Install ONNX stack
pip install onnx onnxruntime-gpu

# 9. Install CV & ML libraries
pip install opencv-python scipy pillow

# 10. Install YOLOX dependencies
pip install thop tabulate tqdm pycocotools

# 11. Install tracking dependencies
pip install lap cython_bbox

# 12. Install utilities
pip install loguru pyyaml python-dotenv

# 13. Install vector database (optional)
pip install qdrant-client

echo "‚úÖ Installation completed!"
```

---

## ‚ö†Ô∏è CRITICAL VERSION CONSTRAINTS

### Version Matrix

| Package | Version | Reason |
|---------|---------|--------|
| Python | **3.10.x** | TensorRT 8.6.1 bindings ch·ªâ c√≥ cho Python 3.10 |
| PyTorch | **2.0.1+cu118** | T∆∞∆°ng th√≠ch CUDNN 8.x |
| TensorRT | **8.6.1.post1** | H·ªó tr·ª£ GPU SM 70 (V100) |
| CUDNN | **8.9.6.50** | Y√™u c·∫ßu c·ªßa TensorRT 8.6.1 |
| NumPy | **< 2.0** | PyTorch 2.0.1 kh√¥ng t∆∞∆°ng th√≠ch NumPy 2.x |
| CUDA | **12.8** | System-wide (compatible v·ªõi cu118 wheels) |

### Dependency Conflicts to Avoid

‚ùå **KH√îNG C√ÄI:**
- PyTorch 2.5.x (y√™u c·∫ßu CUDNN 9.x)
- TensorRT 10.x (kh√¥ng h·ªó tr·ª£ SM 70)
- NumPy 2.x (kh√¥ng t∆∞∆°ng th√≠ch PyTorch 2.0.1)
- Python 3.12 (kh√¥ng c√≥ TensorRT 8.6.1 bindings)
- CUDNN 9.x (kh√¥ng t∆∞∆°ng th√≠ch TensorRT 8.6.1)

---

## üß™ VERIFICATION

### 1. Verify Python Version
```bash
python --version
# Expected: Python 3.10.x
```

### 2. Verify PyTorch
```python
import torch
print(f"PyTorch: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA version: {torch.version.cuda}")
# Expected: 2.0.1+cu118, True, 11.8
```

### 3. Verify TensorRT
```python
import tensorrt as trt
print(f"TensorRT: {trt.__version__}")
# Expected: 8.6.1
```

### 4. Verify CUDNN
```bash
python -c "import torch; print(torch.backends.cudnn.version())"
# Expected: 8906 (CUDNN 8.9.6)
```

### 5. Verify PyCUDA
```python
import pycuda.autoinit
import pycuda.driver as cuda
print(f"PyCUDA initialized: {cuda.Device(0).name()}")
# Expected: Tesla V100-SXM2-16GB
```

### 6. Verify NumPy
```python
import numpy as np
print(f"NumPy: {np.__version__}")
# Expected: 1.26.4 (< 2.0)
```

---

## üöÄ USAGE

### 1. Activate Environment
```bash
source ~/data/hai_venv_py310/bin/activate
cd /home/ubuntu/data/person_reid_system
```

### 2. Run TensorRT Inference
```python
from core.detector_trt import TensorRTDetector

detector = TensorRTDetector(
    engine_path='models/bytetrack_x_mot17_fp16.trt',
    conf_threshold=0.5,
    nms_threshold=0.45,
    test_size=(640, 640)
)

detections = detector.detect(frame)
```

### 3. Run Benchmark
```bash
python tools/benchmark.py \
    --pytorch-model models/bytetrack_x_mot17.pth.tar \
    --tensorrt-engine models/bytetrack_x_mot17_fp16.trt \
    --warmup 10 \
    --iterations 100
```

---

## üêõ TROUBLESHOOTING

### Issue 1: `libcudnn.so.8: cannot open shared object file`
**Solution:**
```bash
pip uninstall -y nvidia-cudnn-cu12
pip install nvidia-cudnn-cu12==8.9.6.50 --no-deps
```

### Issue 2: `Target GPU SM 70 is not supported`
**Solution:** Downgrade TensorRT t·ª´ 10.x xu·ªëng 8.6.1
```bash
pip uninstall -y tensorrt tensorrt_cu12 tensorrt_cu12_libs tensorrt_cu12_bindings
pip install tensorrt==8.6.1.post1 --extra-index-url https://pypi.nvidia.com
```

### Issue 3: `Numpy is not available`
**Solution:** Downgrade NumPy
```bash
pip install "numpy<2"
```

### Issue 4: `Could not find a version that satisfies tensorrt_bindings`
**Solution:** S·ª≠ d·ª•ng Python 3.10 thay v√¨ Python 3.12
```bash
python3.10 -m venv ~/data/hai_venv_py310
source ~/data/hai_venv_py310/bin/activate
```

---

## üìä PERFORMANCE EXPECTATIONS

### Benchmark Results (Tesla V100)

| Metric | PyTorch FP16 | TensorRT FP16 | Improvement |
|--------|--------------|---------------|-------------|
| Latency | 45.63 ms | 35.58 ms | **-22%** |
| FPS | 21.91 | 28.11 | **+28%** |
| Speedup | 1.00x | **1.28x** | - |
| Accuracy | 100% | 100% | Same |

### Expected Speedup on Different GPUs

| GPU | Architecture | SM | Expected Speedup |
|-----|--------------|-----|------------------|
| V100 | Volta | 70 | 1.2-1.5x |
| T4 | Turing | 75 | 2.0-2.5x |
| RTX 3090 | Ampere | 86 | 3.0-4.0x |
| A100 | Ampere | 80 | 3.5-5.0x |

---

## üìù NOTES

1. **Speedup th·∫•p h∆°n mong ƒë·ª£i (1.28x vs 3-5x)** v√¨:
   - GPU V100 (SM 70) c≈©, kh√¥ng t·ªëi ∆∞u cho TensorRT 8.6
   - PyTorch ƒë√£ d√πng FP16 v√† fused model
   - Batch size = 1 (kh√¥ng t·∫≠n d·ª•ng parallel processing)

2. **ƒê·ªÉ tƒÉng speedup:**
   - S·ª≠ d·ª•ng GPU m·ªõi h∆°n (A100, RTX 3090)
   - TƒÉng batch size (n·∫øu use case cho ph√©p)
   - Th·ª≠ INT8 quantization (c·∫ßn calibration dataset)

3. **Environment isolation:**
   - Lu√¥n s·ª≠ d·ª•ng virtual environment ri√™ng
   - Kh√¥ng c√†i TensorRT v√†o system Python
   - Tr√°nh conflict v·ªõi c√°c project kh√°c

---

## üîÑ MAINTENANCE

### Update Dependencies
```bash
# Backup current environment
pip freeze > requirements_backup.txt

# Update specific package (c·∫©n th·∫≠n v·ªõi version constraints)
pip install --upgrade <package>

# Verify after update
python tools/benchmark.py --warmup 5 --iterations 10
```

### Recreate Environment
```bash
# Deactivate current environment
deactivate

# Remove old environment
rm -rf ~/data/hai_venv_py310

# Recreate from scratch
python3.10 -m venv ~/data/hai_venv_py310
source ~/data/hai_venv_py310/bin/activate

# Run installation script (see above)
```

---

## üìû SUPPORT

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ, ki·ªÉm tra theo th·ª© t·ª±:

1. ‚úÖ Python version = 3.10.x
2. ‚úÖ PyTorch version = 2.0.1+cu118
3. ‚úÖ TensorRT version = 8.6.1
4. ‚úÖ CUDNN version = 8.9.6.50
5. ‚úÖ NumPy version < 2.0
6. ‚úÖ CUDA available in PyTorch
7. ‚úÖ GPU SM = 70 (V100)

---

**Last Updated:** 2025-11-11  
**Environment:** Python 3.10 + PyTorch 2.0.1 + TensorRT 8.6.1 + CUDNN 8.9.6.50

